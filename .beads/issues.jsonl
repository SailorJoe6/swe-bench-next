{"id":"swebench-eval-next-119","title":"Step 0: Project scaffolding (dirs + docs index)","status":"closed","priority":1,"issue_type":"task","owner":"sailorjoe6@gmail.com","created_at":"2026-02-10T06:48:26.226252483Z","created_by":"Joe Landers","updated_at":"2026-02-10T06:49:44.296914123Z","closed_at":"2026-02-10T06:49:44.296914123Z","close_reason":"Project scaffolding complete: results/{phase1,phase2,phase3,phase4}, scripts/, docs/ directories created. docs/README.md written with project index."}
{"id":"swebench-eval-next-41p","title":"Run SWE-Agent evaluation on 300 instances","description":"After ARM64 images ready, run full SWE-Agent evaluation.\n\nPREREQUISITES:\n✓ vLLM server running (port 8888, Qwen3-Coder-Next-FP8)\n✓ SWE-Agent 1.1.0 installed\n✓ Config ready: config/qwen3-vllm.yaml\n  - Uses function_calling (not thought_action)\n  - litellm_model_registry.json for model capabilities\n  - instances.deployment.python_standalone_dir=\"\" (avoid build issues)\n⧗ Need 300 ARM64 images (blocked by: swebench-eval-next-yv6)\n\nCOMMAND:\ncd ~/Code/swebench-eval-next \u0026\u0026 source venv/bin/activate\nsweagent run-batch --instances.type swe_bench --instances.subset multilingual --instances.split test --config config/qwen3-vllm.yaml --output_dir results/phase3/full-run\n\nCONSTRAINTS:\n- Single concurrent request (--max-num-seqs 1 in vLLM)\n- Max 2-3 parallel agents\n- Multi-day process (300 instances)\n- Use nohup for background execution\n\nAfter starting, move plans back to ralph/plans/ (unblock project).","status":"open","priority":2,"issue_type":"task","owner":"sailorjoe6@gmail.com","created_at":"2026-02-10T18:05:42.412823871Z","created_by":"Joe Landers","updated_at":"2026-02-10T18:05:42.412823871Z","dependencies":[{"issue_id":"swebench-eval-next-41p","depends_on_id":"swebench-eval-next-yv6","type":"blocks","created_at":"2026-02-10T18:05:47.508942591Z","created_by":"Joe Landers"}]}
{"id":"swebench-eval-next-evs","title":"Phase 1: Qwen3-Coder-Next-FP8 vLLM Setup","description":"Next task to execute. Steps 1.1 and 1.2 can run in parallel. Current environment state: spark-vllm-docker NOT cloned, huggingface-cli NOT installed, model weights NOT downloaded, pre-pulled nvcr.io/nvidia/vllm images exist but must NOT be used (wrong vLLM version per spec). See execution plan Steps 1.1-1.5 for full details.","status":"closed","priority":1,"issue_type":"feature","owner":"sailorjoe6@gmail.com","created_at":"2026-02-10T06:48:30.163085689Z","created_by":"Joe Landers","updated_at":"2026-02-10T07:40:14.570880879Z","closed_at":"2026-02-10T07:40:14.570880879Z","close_reason":"All Phase 1 steps complete: container built, model downloaded, server launched (python3 -m vllm.entrypoints.openai.api_server workaround for vLLM 0.15.x argparse bug), validation 3/3 passed, scripts updated with daemon mode and --logs support","dependencies":[{"issue_id":"swebench-eval-next-evs","depends_on_id":"swebench-eval-next-119","type":"blocks","created_at":"2026-02-10T06:48:38.454255495Z","created_by":"Joe Landers"}]}
{"id":"swebench-eval-next-p9w","title":"Phase 3: SWE-Agent Harness Evaluation","description":"Install SWE-agent, configure for local vLLM, run against SWE-bench Multilingual, evaluate predictions, generate reports","status":"in_progress","priority":2,"issue_type":"feature","owner":"sailorjoe6@gmail.com","created_at":"2026-02-10T06:48:33.017771264Z","created_by":"Joe Landers","updated_at":"2026-02-10T07:54:30.818106305Z","dependencies":[{"issue_id":"swebench-eval-next-p9w","depends_on_id":"swebench-eval-next-qb9","type":"blocks","created_at":"2026-02-10T06:48:38.518568563Z","created_by":"Joe Landers"}]}
{"id":"swebench-eval-next-qb9","title":"Phase 2: SWE-Bench Default Harness Evaluation","description":"Phase 2 - Next task after Phase 1 complete.\n\nCurrent state: vLLM server running on port 8888 (container: vllm_node), validation passed.\n\nStep 2.1 - Install SWE-bench:\n  cd ~/Code \u0026\u0026 git clone https://github.com/SWE-bench/SWE-bench.git\n  cd SWE-bench \u0026\u0026 pip install -e .\n  Verify: python -m swebench.harness.run_evaluation --help\n\nStep 2.2 - Generate predictions via run_api:\n  export OPENAI_API_KEY=dummy OPENAI_BASE_URL=http://localhost:8888/v1\n  python -m swebench.inference.run_api --dataset_name_or_path SWE-bench/SWE-bench_Multilingual --model_name_or_path Qwen/Qwen3-Coder-Next-FP8 --output_dir results/phase2/predictions --split test\n  Note: Long-running (300 instances, single concurrent request). Check for built-in skip/resume logic.\n\nStep 2.3 - Run evaluation: Use swebench.harness.run_evaluation with --max_workers 8, --run_id phase2-default-harness\n\nStep 2.4 - Generate reports: Summary (pass rates by language) + detailed (per-instance). Create script if needed, document in docs/README.md.\n\nSee EXECUTION_PLAN.md steps 2.1-2.4 for full details.","status":"closed","priority":2,"issue_type":"feature","owner":"sailorjoe6@gmail.com","created_at":"2026-02-10T06:48:31.687273465Z","created_by":"Joe Landers","updated_at":"2026-02-10T07:54:10.728689177Z","closed_at":"2026-02-10T07:54:10.728689177Z","close_reason":"Skipping Phase 2 - default harness incompatible with custom vLLM (hardcoded model names in tiktoken). Proceeding directly to Phase 3 (SWE-Agent) as per execution plan decision.","dependencies":[{"issue_id":"swebench-eval-next-qb9","depends_on_id":"swebench-eval-next-evs","type":"blocks","created_at":"2026-02-10T06:48:38.486125032Z","created_by":"Joe Landers"}]}
{"id":"swebench-eval-next-qs2","title":"Phase 4: mini-SWE-agent Evaluation (Optional)","description":"Optional phase. Install mini-SWE-agent, configure for local vLLM, run against SWE-bench Multilingual, evaluate and report. Only after Phase 3 success.","status":"open","priority":4,"issue_type":"feature","owner":"sailorjoe6@gmail.com","created_at":"2026-02-10T06:48:34.415455358Z","created_by":"Joe Landers","updated_at":"2026-02-10T06:48:34.415455358Z","dependencies":[{"issue_id":"swebench-eval-next-qs2","depends_on_id":"swebench-eval-next-p9w","type":"blocks","created_at":"2026-02-10T06:48:38.544511192Z","created_by":"Joe Landers"}]}
{"id":"swebench-eval-next-yv6","title":"Rebuild SWE-bench images as native ARM64","description":"System is NVIDIA Grace (ARM64). Current 274/300 x86_64 images run under QEMU but 26 failed to build (Rust/Go segfaults). Need to rebuild all 300 as native aarch64.\n\nAPPROACH:\n1. Patch SWE-bench prepare_images.py to add --arch CLI parameter\n2. Patch test_spec.py line 180 to use arch from args (currently hardcoded 'x86_64')\n3. Rebuild all 300 with --arch aarch64\n4. Images tagged as sweb.eval.aarch64.* (not x86_64)\n\nFILES:\n- ~/Code/SWE-bench/swebench/harness/prepare_images.py\n- ~/Code/SWE-bench/swebench/harness/test_spec/test_spec.py\n\nCOMMAND:\npython -m swebench.harness.prepare_images --dataset_name SWE-bench/SWE-bench_Multilingual --split test --arch aarch64 --max_workers 4 --namespace swebench --tag latest --env_image_tag latest\n\nEXPECTED: All 300 build successfully (3-6 hrs). Blocks Phase 3 SWE-Agent run.","status":"in_progress","priority":2,"issue_type":"task","owner":"sailorjoe6@gmail.com","created_at":"2026-02-10T18:05:28.831785171Z","created_by":"Joe Landers","updated_at":"2026-02-10T18:13:53.727849384Z"}
