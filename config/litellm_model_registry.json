{
  "openai/Qwen/Qwen3-Coder-Next-FP8": {
    "max_tokens": 262144,
    "max_input_tokens": 199000,
    "max_output_tokens": 65536,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "litellm_provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": false
  }
}
